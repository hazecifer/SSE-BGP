{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.patheffects as path_effects\n",
    "import math\n",
    "import random\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'your_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "categorical_columns = ['Formula', 'Crystal type', 'Inversion_Symmetry', 'Magnetic']\n",
    "numerical_columns = [col for col in data.columns if col not in categorical_columns + ['Formula']]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    data[column] = data[column].astype('category')\n",
    "\n",
    "for column in numerical_columns:\n",
    "    data[column] = pd.to_numeric(data[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'HSE06_Band_Gap'\n",
    "features = [col for col in data.columns if col != target and col != 'Formula']\n",
    "\n",
    "categorical_columns = ['Crystal type', 'Inversion_Symmetry', 'Magnetic']\n",
    "numerical_columns = [col for col in features if col not in categorical_columns]\n",
    "\n",
    "print(\"Categorical_columns：\", categorical_columns)\n",
    "print(\"Numerical_columns：\", numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'HSE06_Band_Gap'\n",
    "features = [col for col in data_encoded.columns if col != target and col != 'Formula']\n",
    "\n",
    "data_numeric = data_encoded[features + [target]]\n",
    "\n",
    "corr_matrix = data_numeric.corr()\n",
    "\n",
    "threshold = 0.15\n",
    "target_corr = corr_matrix[target].abs().sort_values(ascending=False)\n",
    "top_features = target_corr[target_corr > threshold].index.tolist()\n",
    "\n",
    "print(top_features)\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.set(style='white') \n",
    "\n",
    "corr_subset = corr_matrix.loc[top_features, top_features]\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_subset, dtype=bool))\n",
    "\n",
    "#cmap = 'RdGy'  #：'viridis', 'YlGnBu', 'coolwarm'\n",
    "#cmap = sns.color_palette(\"Purples_d\", as_cmap=True)\n",
    "#cmap = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "#cmap = sns.color_palette(\"PuBu\", as_cmap=True)\n",
    "cmap = sns.blend_palette([(255/255, 255/255, 255/255), (70/255, 50/255, 180/255)], as_cmap=True) \n",
    "\n",
    "heatmap = sns.heatmap(\n",
    "    corr_subset,\n",
    "    #annot=True,\n",
    "    #fmt=\".2f\",\n",
    "    cmap=cmap,\n",
    "    linewidths=0.1,\n",
    "    linecolor='white',\n",
    "    #mask=mask,\n",
    "    cbar_kws={\"shrink\": .8},\n",
    "    square=True,\n",
    "    annot_kws={\"size\": 12},\n",
    "    vmin=-1, vmax=1  \n",
    ")\n",
    "\n",
    "plt.title('Correlation Heatmap of Top Features', fontsize=28, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=20)\n",
    "plt.yticks(rotation=0, fontsize=20)\n",
    "\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "for text in heatmap.texts:\n",
    "    text.set_path_effects([\n",
    "        mpl.patheffects.Stroke(linewidth=1, foreground='white'),\n",
    "        mpl.patheffects.Normal()\n",
    "    ])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('correlation_heatmap.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data_numeric.drop([target], axis=1))\n",
    "y = data_numeric[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_regression, k=50)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "selected_feature_names = np.array(data_numeric.drop([ target], axis=1).columns)[selector.get_support()]\n",
    "\n",
    "print(\"Nums：\", X_selected.shape[1])\n",
    "print(\"Fets：\", selected_feature_names.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = selector.scores_\n",
    "feature_importance = pd.DataFrame({'Feature': selected_feature_names, 'Score': feature_scores[selector.get_support()]})\n",
    "print(feature_importance.sort_values(by='Score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99, random_state=42)\n",
    "X_pca = pca.fit_transform(X_selected)\n",
    "print(\"PCA：\", X_pca.shape[1])\n",
    "\n",
    "indices = np.arange(len(data_encoded))\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "    X_pca, y, indices, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim=20):\n",
    "        super(AdvancedAutoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),  \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),  \n",
    "            nn.Linear(256, encoding_dim),\n",
    "            nn.BatchNorm1d(encoding_dim),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),  \n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),  \n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "input_dim_auto = X_train.shape[1]\n",
    "encoding_dim = 30  \n",
    "autoencoder = AdvancedAutoencoder(input_dim=input_dim_auto, encoding_dim=encoding_dim)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.0001, weight_decay=1e-6)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, X_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200  \n",
    "patience = 15  \n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "history_loss = []\n",
    "history_val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    running_loss = 0.0\n",
    "    for data, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(data)\n",
    "        loss = criterion(outputs, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    autoencoder.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            outputs = autoencoder(data)\n",
    "            loss = criterion(outputs, data)\n",
    "            val_running_loss += loss.item() * data.size(0)\n",
    "    val_epoch_loss = val_running_loss / len(test_loader.dataset)\n",
    "    \n",
    "    history_loss.append(epoch_loss)\n",
    "    history_val_loss.append(val_epoch_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        patience_counter = 0\n",
    "        \n",
    "        best_model_state = autoencoder.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "\n",
    "autoencoder.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "with torch.no_grad():\n",
    "    X_train_encoded = autoencoder.encoder(X_train_tensor).numpy()\n",
    "    X_test_encoded = autoencoder.encoder(X_test_tensor).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_train_encoded[:, 0], y=X_train_encoded[:, 1], hue=y_train, palette='viridis')\n",
    "plt.title(\"Encoded Features of Training Set\")\n",
    "plt.xlabel(\"Encoded Feature 1\")\n",
    "plt.ylabel(\"Encoded Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reconstructed = autoencoder.decoder(torch.tensor(X_train_encoded, dtype=torch.float32)).detach().numpy()\n",
    "reconstruction_loss = np.mean(np.square(X_train_tensor.numpy() - X_train_reconstructed))\n",
    "print(f\"Training Reconstruction Loss: {reconstruction_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.to_csv('Encoded_train_data.csv', index=False)\n",
    "X_test_encoded.to_csv('Encoded_test_data.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
